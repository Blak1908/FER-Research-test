{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anishjohnson/Face-Emotion-Recognition/blob/main/FER/Colab%20Notebook/Face_Emotion_Recognition_Anish_Johnson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URwdYfsiMltF"
      },
      "source": [
        "# **Face Emotion Recognition**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5RpZlMkPGG2"
      },
      "source": [
        "# **Objective**\n",
        "Our objective is to solve the above mentioned challenge by applying deep learning algorithms to live video data inorder to recognize the facial emotions and categorize them accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AGaR26YPV--"
      },
      "source": [
        "# **Dataset used**\n",
        "We have utilized the [FER 2013](https://www.kaggle.com/datasets/msambare/fer2013) dataset provided on Kaggle.<br>\n",
        "The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image.<br>\n",
        "\n",
        "The task is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set consists of 28,709 examples and the public test set consists of 3,589 examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVjAMoriVm5s"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "!nvcc -V"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKaCCukeQGGv"
      },
      "source": [
        "### **Let's Begin:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2QTffm_tEDK"
      },
      "source": [
        "# **Data Exploration:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5py4G2_K3R3Y"
      },
      "source": [
        "**Lets start by importing the required libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OheLkRm1DJ3a"
      },
      "outputs": [],
      "source": [
        "# Basic python libraries.\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import itertools\n",
        "\n",
        "# Get rid of warnings!\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep learning libraries.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "print('Above libraries have been imported.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ynAHGserFiTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKEJMNa45tfB"
      },
      "source": [
        "**Seperate the Training and Validation Data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnFhfDs6sobL"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Project-AI/Dataset/FER-2013-Dataset.zip'\n",
        "# Load the FER2013 dataset\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(file_path , 'r') as ZipFile:\n",
        "  ZipFile.extractall()\n",
        "  print('Zip file extracted successfully')"
      ],
      "metadata": {
        "id": "qgCa-42EGDhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKpeEhrw5sSN"
      },
      "outputs": [],
      "source": [
        "# Define the train and validataion data paths.\n",
        "train_dir = '/content/train'\n",
        "val_dir = '/content/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bzIXm5UjD-p"
      },
      "outputs": [],
      "source": [
        "# Define the default image size.\n",
        "img_size = 48\n",
        "\n",
        "# Define the seven emotions provided in dataset.\n",
        "emotion_list = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
        "\n",
        "# Plot the images with each distinct emotions.\n",
        "plt.figure(figsize=(18,22))\n",
        "i = 1\n",
        "for expression in emotion_list:\n",
        "    img = load_img((train_dir + '/' + expression +'/'+ os.listdir(train_dir + '/' + expression)[59]))\n",
        "    plt.subplot(1,7,i)\n",
        "    plt.imshow(img)\n",
        "    plt.title(expression)\n",
        "    plt.axis('off')\n",
        "    i += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Duo9uIT3PV6"
      },
      "source": [
        "**Have a look at our data.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNCuMOZrGkcx"
      },
      "source": [
        "**Perform some Data Augmentation on train and validations sets.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvy5uusVtMAh"
      },
      "source": [
        "# **Data Preprocessing:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnZfATJ1GW5T"
      },
      "outputs": [],
      "source": [
        "# Rescale the data.\n",
        "'''\n",
        "Before we proceed we need to rescale our data by multiplying it to 1/255.\n",
        "This is done so we get target values between 0 and 1.\n",
        "'''\n",
        "# Rescale train data.\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Rescale validation data.\n",
        "datagen_val = ImageDataGenerator(rescale = 1./255,\n",
        "                                 )\n",
        "\n",
        "print('Above data generator functions have been created.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfQSzCIDGWvq"
      },
      "outputs": [],
      "source": [
        "# Perform data augmentation.\n",
        "'''\n",
        "Data augmentation is a technique to artificially create new training data from existing training data. \n",
        "It helps us to increase the size of the dataset and introduce variability in the dataset.\n",
        "'''\n",
        "# Define the default image size.\n",
        "img_size = 48\n",
        "\n",
        "# Define batch size.\n",
        "batch_size = 64\n",
        "\n",
        "                                         \n",
        "# Train data\n",
        "train_set = datagen_train.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation data\n",
        "val_set = datagen_train.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n",
        "print('Train and Validation sets have been created.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNBzIZBDQbAm"
      },
      "source": [
        "**Now lets create our custom CNN model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOwMRBUFuHnp"
      },
      "source": [
        "# **Build CNN Model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK5yRfKO2r53"
      },
      "source": [
        "**Before we start building the neural network lets understand some of the terms that we will be using.**\n",
        "\n",
        "* **Model = sequential** : A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
        "\n",
        "* **Padding** = The padding parameter of the Keras Conv2D class can take one of two values: 'valid' or 'same'. Setting the value to “valid” parameter means that the input volume is not zero-padded and the spatial dimensions are allowed to reduce via the natural application of convolution.\n",
        "\n",
        "* **Activation** = relu :The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. It has become the default activation function for many types of neural networks because a model that uses it is easier to train and often achieves better performance.\n",
        "\n",
        "* **Maxpooling** = Maximum pooling, or max pooling, is a pooling operation that calculates the maximum, or largest, value in each patch of each feature map. The results are down sampled or pooled feature maps that highlight the most present feature in the patch, not the average presence of the feature in the case of average pooling.\n",
        "\n",
        "* **Batch normalization** = Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.\n",
        "\n",
        "* **Dropout** = Dropout is a technique used to prevent a model from overfitting. Dropout works by randomly setting the outgoing edges of hidden units (neurons that make up hidden layers) to 0 at each update of the training phase.\n",
        "\n",
        "* **Adam** = Adaptive Moment Estimation is an algorithm for optimization technique for gradient descent. The method is really efficient when working with large problem involving a lot of data or parameters. It requires less memory and is efficient. Intuitively, it is a combination of the ‘gradient descent with momentum’ algorithm and the ‘RMSP’ algorithm. It uses the squared gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself like SGD with momentum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rC4qfWffxRX"
      },
      "outputs": [],
      "source": [
        "# AlexNet model\n",
        "\n",
        "class AlexNet(Sequential):\n",
        "  def __init__(self, input_shape, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.add(Conv2D(64, kernel_size = (3,3),\n",
        "                    strides= 2, \n",
        "                    padding = 'valid', \n",
        "                    activation = 'relu',\n",
        "                    input_shape= input_shape,\n",
        "                    kernel_initializer= 'he_normal'\n",
        "                    ))\n",
        "    \n",
        "    self.add(MaxPooling2D(pool_size=(3,3), \n",
        "                          strides= (2,2),\n",
        "                          padding= 'valid', \n",
        "                          data_format= None))\n",
        "\n",
        "    self.add(Conv2D(128, kernel_size=(3,3), \n",
        "                    strides= 1,\n",
        "                    padding= 'same', \n",
        "                    activation= 'relu',\n",
        "                    kernel_initializer= 'he_normal'))\n",
        "    \n",
        "    self.add(MaxPooling2D(pool_size=(3,3), \n",
        "                          strides= (2,2),\n",
        "                          padding= 'valid', \n",
        "                          data_format= None)) \n",
        "\n",
        "    self.add(Conv2D(256, kernel_size=(3,3), \n",
        "                    strides= 1,\n",
        "                    padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "    \n",
        "    self.add(MaxPooling2D(pool_size=(3,3), \n",
        "                          strides= (2,2),\n",
        "                          padding= 'valid', \n",
        "                          data_format= None)) \n",
        "\n",
        "    self.add(Conv2D(512, kernel_size=(3,3), \n",
        "                    strides= 1,\n",
        "                    padding= 'same', \n",
        "                    activation= 'relu',\n",
        "                    kernel_initializer= 'he_normal'))\n",
        "\n",
        "    self.add(MaxPooling2D(pool_size=(2,2), \n",
        "                          strides= (2,2),\n",
        "                          padding= 'valid', \n",
        "                          data_format= None))\n",
        "\n",
        "    self.add(Flatten())\n",
        "    self.add(Dense(4096, activation= 'relu'))\n",
        "    self.add(Dense(4096, activation= 'relu'))\n",
        "    self.add(Dense(1000, activation= 'relu'))\n",
        "    self.add(Dense(1000, activation= 'relu'))\n",
        "    self.add(Dense(1000, activation= 'relu'))\n",
        "    self.add(Dense(1000, activation= 'relu'))\n",
        "    self.add(Dense(num_classes, activation= 'softmax'))\n",
        "\n",
        "    opt = SGD(lr=0.01)\n",
        "    self.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkUwk3w2fxRX"
      },
      "outputs": [],
      "source": [
        "class VGGNet(Sequential):\n",
        "  def __init__(self, input_shape, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(48, 48, 3)))\n",
        "    self.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    self.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    self.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    self.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    self.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    self.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    self.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    self.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(Flatten())\n",
        "    self.add(Dense(4096, activation='relu'))\n",
        "    self.add(Dense(4096, activation='relu'))\n",
        "    self.add(Dense(4096, activation='relu'))\n",
        "    self.add(Dense(4096, activation='relu'))\n",
        "    self.add(Dense(1000, activation='relu'))\n",
        "    self.add(Dense(1000, activation='relu'))\n",
        "    self.add(Dense(num_classes, activation='softmax'))\n",
        "    opt = SGD(lr=0.02)\n",
        "    self.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX1OE3iXfxRX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Add, GlobalAveragePooling2D,Dense, Flatten, Conv2D, Lambda,\tInput, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import schedules, SGD\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "\n",
        "\n",
        "def model_configuration():\n",
        "\n",
        "\n",
        "## Load dataset for computing dataset size\n",
        "#(input_train, ), (, _) = load_dataset()\n",
        "# Generic config\n",
        "    width, height, channels = 48, 48, 3\n",
        "    batch_size = 128\n",
        "    num_classes = 7\n",
        "# validation_split = 0.1 # 45/5 per the He et al. paper\n",
        "    verbose = 1\n",
        "    n = 3\n",
        "    init_fm_dim = 64\n",
        "    shortcut_type = \"identity\" # or: projection\n",
        "\n",
        "# \t# Dataset size\n",
        "# \ttrain_size = (1 - validation_split) * len(input_train) \n",
        "# \tval_size = (validation_split) * len(input_train) \n",
        "\n",
        "# Number of steps per epoch is dependent on batch size\n",
        "# maximum_number_iterations = 64000 # per the He et al. paper\n",
        "# steps_per_epoch = tensorflow.math.floor(train_size / batch_size)\n",
        "# val_steps_per_epoch = tensorflow.math.floor(val_size / batch_size)\n",
        "#epochs = tensorflow.cast(tensorflow.math.floor(maximum_number_iterations / steps_per_epoch),\\\n",
        "# dtype=tensorflow.int64)\n",
        "\n",
        "# Define loss function\n",
        "    loss = tensorflow.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    # Learning rate config per the He et al. paper\n",
        "    boundaries = [32000, 48000]\n",
        "    values = [0.1, 0.01, 0.001]\n",
        "    lr_schedule = schedules.PiecewiseConstantDecay(boundaries, values)\n",
        "\n",
        "# Set layer init\n",
        "    initializer = tensorflow.keras.initializers.HeNormal()\n",
        "\n",
        "# Define optimizer\n",
        "    optimizer_momentum = 0.9\n",
        "    optimizer_additional_metrics = [\"accuracy\"]\n",
        "    optimizer = SGD(learning_rate=lr_schedule, momentum=optimizer_momentum)\n",
        "\n",
        "# Load Tensorboard callback\n",
        "    tensorboard = TensorBoard(\n",
        "      log_dir=os.path.join(os.getcwd(), \"logs\"),\n",
        "      histogram_freq=1,\n",
        "      write_images=True\n",
        "            )\n",
        "\n",
        "# Save a model checkpoint after every epoch\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        os.path.join(os.getcwd(), \"model_checkpoint\"),\n",
        "        save_freq=\"epoch\"\n",
        ")\n",
        "\n",
        "# Add callbacks to list\n",
        "    callbacks = [\n",
        "          tensorboard,\n",
        "          checkpoint\n",
        "                ]\n",
        "\n",
        "# Create config dictionary\n",
        "    config = {\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "        \"dim\": channels,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"num_classes\": num_classes,\n",
        "        \"validation_split\": val_set,\n",
        "        \"verbose\": verbose,\n",
        "        \"stack_n\": n,\n",
        "        \"initial_num_feature_maps\": init_fm_dim,\n",
        "        # \"training_ds_size\": train_size,\n",
        "        # \"steps_per_epoch\": steps_per_epoch,\n",
        "        # \"val_steps_per_epoch\": val_steps_per_epoch,\n",
        "        # \"num_epochs\": epochs,\n",
        "        \"loss\": loss,\n",
        "        \"optim\": optimizer,\n",
        "        \"optim_learning_rate_schedule\": lr_schedule,\n",
        "        \"optim_momentum\": optimizer_momentum,\n",
        "        \"optim_additional_metrics\": optimizer_additional_metrics,\n",
        "        \"initializer\": initializer,\n",
        "        \"callbacks\": callbacks,\n",
        "        \"shortcut_type\": shortcut_type\n",
        "    }\n",
        "    return config\n",
        "\n",
        "def residual_block(x, number_of_filters, match_filter_size=False):\n",
        "    \n",
        "    \n",
        "    # Retrieve initializer\n",
        "    config = model_configuration()\n",
        "    initializer = config.get(\"initializer\")\n",
        "    # Create skip connection\n",
        "    x_skip = x\n",
        "\n",
        "    # Perform the original mapping\n",
        "    if match_filter_size:\n",
        "        x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(2,2),\n",
        "                   kernel_initializer=initializer, padding=\"same\")(x_skip)\n",
        "    else:\n",
        "        x = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(1,1), \n",
        "                   kernel_initializer=initializer, padding=\"same\")(x_skip)\n",
        "        \n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(number_of_filters, kernel_size=(3, 3),kernel_initializer=initializer, padding=\"same\")(x)\n",
        "    x = BatchNormalization(axis=3)(x)\n",
        "\n",
        "    # Perform matching of filter numbers if necessary\n",
        "    if match_filter_size and config.get(\"shortcut_type\") == \"identity\":\n",
        "        x_skip = Lambda(lambda x: tensorflow.pad(x[:, ::2, ::2, :], tensorflow.constant([[0, 0,], [0, 0], [0, 0], [number_of_filters//4, number_of_filters//4]]), mode=\"CONSTANT\"))(x_skip)\n",
        "    elif match_filter_size and config.get(\"shortcut_type\") == \"projection\":  \n",
        "        x_skip = Conv2D(number_of_filters, kernel_size=(1,1),kernel_initializer=initializer, strides=(2,2))(x_skip)\n",
        "    # Add the skip connection to the regular mapping \n",
        "    x = Add()([x, x_skip])\n",
        "\n",
        "    # Nonlinearly activate the result\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # Return the result\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def ResidualBlocks(x):\n",
        "  # Retrieve values \n",
        "    config = model_configuration()\n",
        "  # Set initial filter size\n",
        "    filter_size = config.get(\"initial_num_feature_maps\")\n",
        "\n",
        "\n",
        "    for layer_group in range(3):\n",
        "        for block in range(config.get(\"stack_n\")):\n",
        "            if layer_group > 0 and block == 0:\n",
        "                filter_size *= 2\n",
        "                x = residual_block(x, filter_size, match_filter_size=True)\n",
        "            else:\n",
        "                x = residual_block(x, filter_size)\n",
        "\n",
        "    return x\n",
        "\n",
        "def model_base(shp):\n",
        "  # Get number of classes from model configuration\n",
        "    config = model_configuration()\n",
        "    initializer = model_configuration().get(\"initializer\")\n",
        "\n",
        "    # Define model structure\n",
        "    # logits are returned because Softmax is pushed to loss function.\n",
        "    inputs = Input(shape=shp)\n",
        "    x = Conv2D(config.get(\"initial_num_feature_maps\"), kernel_size=(3,3),\\\n",
        "        strides=(1,1), kernel_initializer=initializer, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = ResidualBlocks(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(config.get(\"num_classes\"), kernel_initializer=initializer)(x)\n",
        "\n",
        "    return inputs, outputs\n",
        "    \n",
        "\n",
        "def ResNet():\n",
        "  # Get shape from model configuration\n",
        "    config = model_configuration()\n",
        "  # Get model base\n",
        "    inputs, outputs = model_base((config.get(\"width\"), config.get(\"height\"),config.get(\"dim\")))\n",
        "  # Initialize and compile mode\n",
        "\n",
        "    model = Model(inputs, outputs, name=config.get(\"name\"))\n",
        "    model.compile(loss=config.get(\"loss\"),optimizer=config.get(\"optim\"), metrics=config.get(\"optim_additional_metrics\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnxVTMKcGWjd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "label_dict = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\n",
        "\n",
        "# Define model architecture\n",
        "model_AlexNet = AlexNet((48,48,3), 7)\n",
        "model_VGGNet = VGGNet((48,48,3), 7)\n",
        "model_ResNet = ResNet()\n",
        "    \n",
        "# Load weights model\n",
        "model_AlexNet.load_weights('/content/drive/MyDrive/model_saved/AlexNet-model/AlexNet_model_weighs.h5')\n",
        "model_VGGNet.load_weights('/content/drive/MyDrive/model_saved/VGGNet-model/VGGNet_weights.h5')\n",
        "model_ResNet.load_weights('/content/drive/MyDrive/model_saved/Resnet-model/resNet_model_weighs-20iters.h5')\n",
        "\n",
        "alexnet_preds = model_AlexNet.predict(val_set)\n",
        "vggnet_preds = model_VGGNet.predict(val_set)\n",
        "resnet_preds = model_ResNet.predict(val_set)\n",
        "\n",
        "combined_preds = np.concatenate((alexnet_preds, vggnet_preds, resnet_preds), axis=1)\n",
        "\n",
        "# Train an SVM classifier on the combined predictions\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(combined_preds, val_set.labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('model.pkl','wb') as f:\n",
        "    pickle.dump(svm_model,f)\n"
      ],
      "metadata": {
        "id": "B_v8qDv-Jtrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = \"/content/test/happy/PrivateTest_10077120.jpg\""
      ],
      "metadata": {
        "id": "OJTzm3txFFtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the SVM model\n",
        "with open('model.pkl', 'rb') as f:\n",
        "    svm_loaded = pickle.load(f)\n",
        "\n",
        "# Load and preprocess the test image\n",
        "img = image.load_img(\"/content/test/disgust/PrivateTest_11895083.jpg\", target_size=(48, 48))\n",
        "img = image.img_to_array(img)\n",
        "img = img / 255.0\n",
        "img = np.expand_dims(img, axis=0)\n",
        "    \n",
        "# Obtain predictions from the pre-trained models\n",
        "alexnet_pred = model_AlexNet.predict(img)\n",
        "vggnet_pred = model_VGGNet.predict(img)\n",
        "resnet_pred = model_ResNet.predict(img)\n",
        "    \n",
        "# Concatenate the predictions\n",
        "combined_pred = np.concatenate((alexnet_pred, vggnet_pred, resnet_pred), axis=1)\n",
        "    \n",
        "    \n",
        "# Use the SVM model to predict the class label\n",
        "    \n",
        "svm_pred = svm_loaded.predict(combined_pred)\n",
        "    \n",
        "predicted_label = label_dict[svm_pred[0]]\n",
        "print(predicted_label)"
      ],
      "metadata": {
        "id": "IU3HSxGJE30T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnmN7X0Lt88s"
      },
      "source": [
        "#Save model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRQ3-GAkutyh"
      },
      "source": [
        "# **Model evaluation:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqi6dYuevD74"
      },
      "outputs": [],
      "source": [
        "# Using Tensorboard \n",
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OirCn85XRRjJ"
      },
      "outputs": [],
      "source": [
        "# Or using plotting \n",
        "# Create plots for accuracy and loss.\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "fig.set_size_inches(12,4)\n",
        "\n",
        "ax[0].plot(history.history['accuracy'])\n",
        "ax[0].plot(history.history['val_accuracy'])\n",
        "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_title('Training Loss vs Validation Loss')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_4f0pr_MvTf"
      },
      "outputs": [],
      "source": [
        "# Create confusion matrix of our predictions\n",
        "\n",
        "# compute predictions\n",
        "predictions = model.predict_generator(generator=val_set)\n",
        "y_pred = [np.argmax(probas) for probas in predictions]\n",
        "y_test = val_set.classes\n",
        "class_names = val_set.class_indices.keys()\n",
        "\n",
        "# Create function to plot confussion matrix.\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    plt.figure(figsize=(12,6), dpi=120)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')# **Live Class Monitoring System(Face Emotion Recognition)**\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Normalized confusion matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpwLo3MOVlo_"
      },
      "source": [
        "## Pretrain Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V69pX_lbVp0U"
      },
      "source": [
        "Load model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgloycjsVovY"
      },
      "source": [
        "loaded_model = load_model(\"AlexNet_model-100iters.h5\")\n",
        "loaded_model.load_weights(\"AlexNet_model_weights-100iters.h5\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "URwdYfsiMltF",
        "g5RpZlMkPGG2"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}